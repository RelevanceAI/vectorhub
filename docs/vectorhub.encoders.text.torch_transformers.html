

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>vectorhub.encoders.text.torch_transformers package &mdash; VectorHub 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="vectorhub.encoders.text.vectorai package" href="vectorhub.encoders.text.vectorai.html" />
    <link rel="prev" title="vectorhub.encoders.text.tfhub package" href="vectorhub.encoders.text.tfhub.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> VectorHub
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">What is Vector Hub?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how_to_add_a_model.html">How To Add Your Model To Vector Hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_encoder.html">Guide to using Auto-Encoder</a></li>
</ul>
<p class="caption"><span class="caption-text">Text Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.bert2vec.html">Bert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.albert2vec.html">AlBert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.labse2vec.html">LaBSE2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.use2vec.html">USE2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.use_multi2vec.html">USEMulti2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.legalbert2vec.html">LegalBert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.transformer2vec.html">Transformer2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.sentencetransformer2vec.html">SentenceTransformer2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.vectorai2vec.html">ViText2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Image Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.bit2vec.html">Bit2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.inception2vec.html">Inception2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.resnet2vec.html">ResNet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.inception_resnet2vec.html">InceptionResnet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.mobilenet2vec.html">MobileNet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.vectorai2vec.html">ViImage2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.speech_embedding2vec.html">SpeechEmbedding2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.trill2vec.html">Trill2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.vggish2vec.html">Vggish2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.yamnet2vec.html">Yamnet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.wav2vec.html">Wav2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.vectorai2vec.html">ViAudio2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Text Bi-Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.use_qa2vec.html">USEQA2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.lareqa_qa2vec.html">LAReQA2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.dpr2vec.html">DPR2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Modules</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">vectorhub</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="vectorhub.html">vectorhub package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="vectorhub.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="vectorhub.bi_encoders.html">vectorhub.bi_encoders package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="vectorhub.encoders.html">vectorhub.encoders package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.auto_encoder">vectorhub.auto_encoder module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.base">vectorhub.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.doc_utils">vectorhub.doc_utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.errors">vectorhub.errors module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.import_utils">vectorhub.import_utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.models_dict">vectorhub.models_dict module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub.utils">vectorhub.utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="vectorhub.html#module-vectorhub">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">VectorHub</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="modules.html">vectorhub</a> &raquo;</li>
        
          <li><a href="vectorhub.html">vectorhub package</a> &raquo;</li>
        
          <li><a href="vectorhub.encoders.html">vectorhub.encoders package</a> &raquo;</li>
        
          <li><a href="vectorhub.encoders.text.html">vectorhub.encoders.text package</a> &raquo;</li>
        
      <li>vectorhub.encoders.text.torch_transformers package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/vectorhub.encoders.text.torch_transformers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="vectorhub-encoders-text-torch-transformers-package">
<h1>vectorhub.encoders.text.torch_transformers package<a class="headerlink" href="#vectorhub-encoders-text-torch-transformers-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-vectorhub.encoders.text.torch_transformers.legal_bert">
<span id="vectorhub-encoders-text-torch-transformers-legal-bert-module"></span><h2>vectorhub.encoders.text.torch_transformers.legal_bert module<a class="headerlink" href="#module-vectorhub.encoders.text.torch_transformers.legal_bert" title="Permalink to this headline">¶</a></h2>
<p><strong>Model Name</strong>: Legal Bert</p>
<p><strong>Vector Length</strong>: 768 (default)</p>
<p><strong>Description</strong>:
BERT has achieved impressive performance in several NLP tasks. However, there has been limited investigation on its adaptation guidelines in specialised domains. Here we focus on the legal domain, where we explore several approaches for applying BERT models to downstream legal tasks, evaluating on multiple datasets. Our findings indicate that the previous guidelines for pre-training and fine-tuning, often blindly followed, do not always generalize well in the legal domain. Thus we propose a systematic investigation of the available strategies when applying BERT in specialised domains. These are: (a) use the original BERT out of the box, (b) adapt BERT by additional pre-training on domain-specific corpora, and (c) pre-train BERT from scratch on domain-specific corpora. We also propose a broader hyper-parameter search space when fine-tuning for downstream tasks and we release LEGAL-BERT, a family of BERT models intended to assist legal NLP research, computational law, and legal technology applications.</p>
<p><strong>Paper</strong>: <a class="reference external" href="https://arxiv.org/abs/2010.02559">https://arxiv.org/abs/2010.02559</a></p>
<p><strong>Repository</strong>: <a class="reference external" href="https://huggingface.co/nlpaueb/legal-bert-base-uncased">https://huggingface.co/nlpaueb/legal-bert-base-uncased</a></p>
<p><strong>Architecture</strong>: Not stated.</p>
<p><strong>Tasks</strong>: Not stated.</p>
<p><strong>Release Date</strong>: 2020-10-06</p>
<p><strong>Limitations</strong>: Not stated.</p>
<p><strong>Installation</strong>: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-text-torch-transformers]</span></code></p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">#pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-text-torch-transformers]</span>
<span class="pre">from</span> <span class="pre">vectorhub.encoders.text.torch_transformers</span> <span class="pre">import</span> <span class="pre">LegalBert2Vec</span>
<span class="pre">model</span> <span class="pre">=</span> <span class="pre">LegalBert2Vec()</span>
<span class="pre">model.encode(&quot;I</span> <span class="pre">enjoy</span> <span class="pre">taking</span> <span class="pre">long</span> <span class="pre">walks</span> <span class="pre">along</span> <span class="pre">the</span> <span class="pre">beach</span> <span class="pre">with</span> <span class="pre">my</span> <span class="pre">dog.&quot;)</span>
<span class="pre">`</span></code></p>
<dl class="py class">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec">
<em class="property">class </em><code class="sig-prename descclassname">vectorhub.encoders.text.torch_transformers.legal_bert.</code><code class="sig-name descname">LegalBert2Vec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'nlpaueb/legal-bert-base-uncased'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="vectorhub.encoders.text.html#vectorhub.encoders.text.base.BaseText2Vec" title="vectorhub.encoders.text.base.BaseText2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">vectorhub.encoders.text.base.BaseText2Vec</span></code></a></p>
<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.bulk_encode">
<code class="sig-name descname">bulk_encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">texts</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>List<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.bulk_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode multiple sentences using transformers.
:param texts: List[str]</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.chunk">
<em class="property">classmethod </em><code class="sig-name descname">chunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lst</span><span class="p">:</span> <span class="n">List</span></em>, <em class="sig-param"><span class="n">chunk_size</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Chunk an iterable object in Python but not a pandas DataFrame.
:param lst: Python List
:param chunk_size: The chunk size of an object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">documents</span> <span class="o">=</span> <span class="p">[{</span><span class="o">...</span><span class="p">}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ViClient</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.definition">
<code class="sig-name descname">definition</code><em class="property"> = &lt;vectorhub.doc_utils.ModelDefinition object&gt;</em><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.definition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>float<span class="p">]</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode words using transformers.
:param text: str</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.is_url_working">
<em class="property">static </em><code class="sig-name descname">is_url_working</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">url</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.is_url_working" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.list_possible_models">
<em class="property">static </em><code class="sig-name descname">list_possible_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.list_possible_models" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.read">
<code class="sig-name descname">read</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.read" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract method to specify the read method to read the data.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.test_word">
<em class="property">property </em><code class="sig-name descname">test_word</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.test_word" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.urls">
<em class="property">property </em><code class="sig-name descname">urls</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.urls" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.validate_model_url">
<em class="property">classmethod </em><code class="sig-name descname">validate_model_url</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_url</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">list_of_urls</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.validate_model_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate the model url belongs in the list of urls. This is to help
users to avoid mis-spelling the name of the model.</p>
<p># TODO:
Improve model URL validation to not include final number in URl string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_url</strong> – The URl of the the model in question</p></li>
<li><p><strong>list_of_urls</strong> – The list of URLS for the model in question</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.vector_length">
<em class="property">property </em><code class="sig-name descname">vector_length</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.legal_bert.LegalBert2Vec.vector_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the vector length of the model.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-vectorhub.encoders.text.torch_transformers.torch_auto_transformers">
<span id="vectorhub-encoders-text-torch-transformers-torch-auto-transformers-module"></span><h2>vectorhub.encoders.text.torch_transformers.torch_auto_transformers module<a class="headerlink" href="#module-vectorhub.encoders.text.torch_transformers.torch_auto_transformers" title="Permalink to this headline">¶</a></h2>
<p><strong>Model Name</strong>: Transformer Models</p>
<p><strong>Vector Length</strong>: Depends on model.</p>
<p><strong>Description</strong>:
These are Tensorflow Automodels from HuggingFace.</p>
<p><strong>Paper</strong>: <a class="reference external" href="https://arxiv.org/abs/1910.03771">https://arxiv.org/abs/1910.03771</a></p>
<p><strong>Repository</strong>: <a class="reference external" href="https://huggingface.co/transformers/pretrained_models.html">https://huggingface.co/transformers/pretrained_models.html</a></p>
<p><strong>Architecture</strong>: Not stated.</p>
<p><strong>Tasks</strong>: Not stated.</p>
<p><strong>Release Date</strong>: None</p>
<p><strong>Limitations</strong>: Not stated.</p>
<p><strong>Installation</strong>: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-text-torch-transformers-auto]</span></code></p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">#pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-text-tf-transformers]</span>
<span class="pre">from</span> <span class="pre">vectorhub.encoders.text.tf_transformers</span> <span class="pre">import</span> <span class="pre">TFTransformer2Vec</span>
<span class="pre">model</span> <span class="pre">=</span> <span class="pre">TFTransformer2Vec('bert-base-uncased')</span>
<span class="pre">model.encode(&quot;I</span> <span class="pre">enjoy</span> <span class="pre">taking</span> <span class="pre">long</span> <span class="pre">walks</span> <span class="pre">along</span> <span class="pre">the</span> <span class="pre">beach</span> <span class="pre">with</span> <span class="pre">my</span> <span class="pre">dog.&quot;)</span>
<span class="pre">`</span></code></p>
<dl class="py class">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec">
<em class="property">class </em><code class="sig-prename descclassname">vectorhub.encoders.text.torch_transformers.torch_auto_transformers.</code><code class="sig-name descname">Transformer2Vec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="vectorhub.encoders.text.html#vectorhub.encoders.text.base.BaseText2Vec" title="vectorhub.encoders.text.base.BaseText2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">vectorhub.encoders.text.base.BaseText2Vec</span></code></a></p>
<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.bulk_encode">
<code class="sig-name descname">bulk_encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">texts</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>List<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.bulk_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode multiple sentences using transformers.
:param Sentences: List[str]</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.chunk">
<em class="property">classmethod </em><code class="sig-name descname">chunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lst</span><span class="p">:</span> <span class="n">List</span></em>, <em class="sig-param"><span class="n">chunk_size</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Chunk an iterable object in Python but not a pandas DataFrame.
:param lst: Python List
:param chunk_size: The chunk size of an object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">documents</span> <span class="o">=</span> <span class="p">[{</span><span class="o">...</span><span class="p">}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ViClient</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.definition">
<code class="sig-name descname">definition</code><em class="property"> = &lt;vectorhub.doc_utils.ModelDefinition object&gt;</em><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.definition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>float<span class="p">]</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode words using transformers.
:param word: str</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.is_url_working">
<em class="property">static </em><code class="sig-name descname">is_url_working</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">url</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.is_url_working" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.read">
<code class="sig-name descname">read</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.read" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract method to specify the read method to read the data.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.test_word">
<em class="property">property </em><code class="sig-name descname">test_word</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.test_word" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.urls">
<em class="property">property </em><code class="sig-name descname">urls</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.urls" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.validate_model_url">
<em class="property">classmethod </em><code class="sig-name descname">validate_model_url</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_url</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">list_of_urls</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.validate_model_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate the model url belongs in the list of urls. This is to help
users to avoid mis-spelling the name of the model.</p>
<p># TODO:
Improve model URL validation to not include final number in URl string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_url</strong> – The URl of the the model in question</p></li>
<li><p><strong>list_of_urls</strong> – The list of URLS for the model in question</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.vector_length">
<em class="property">property </em><code class="sig-name descname">vector_length</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.Transformer2Vec.vector_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the vector length of the model.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="vectorhub.encoders.text.torch_transformers.torch_auto_transformers.list_tested_transformer_models">
<code class="sig-prename descclassname">vectorhub.encoders.text.torch_transformers.torch_auto_transformers.</code><code class="sig-name descname">list_tested_transformer_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_auto_transformers.list_tested_transformer_models" title="Permalink to this definition">¶</a></dt>
<dd><p>List the transformed models.</p>
</dd></dl>

</div>
<div class="section" id="module-vectorhub.encoders.text.torch_transformers.torch_longformers">
<span id="vectorhub-encoders-text-torch-transformers-torch-longformers-module"></span><h2>vectorhub.encoders.text.torch_transformers.torch_longformers module<a class="headerlink" href="#module-vectorhub.encoders.text.torch_transformers.torch_longformers" title="Permalink to this headline">¶</a></h2>
<p><strong>Model Name</strong>: Longformer</p>
<p><strong>Vector Length</strong>: 768 (default)</p>
<p><strong>Description</strong>:
From the abstract of the paper:</p>
<p>Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer’s attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.</p>
<p>Novelties in the LongFormer paper come from its use of attention pattern:</p>
<ul class="simple">
<li><p>Sliding Window: The attention pattern employes fixed-size window attention surrounding each token on both sides.</p></li>
<li><p>Dilated Sliding Window: Similar to CNN dilation, sliding windows can be dilated (i.e. have gaps)</p></li>
<li><p>Global Attention: Certain tokens attend to all tokens (e.g. for classification, global attention is used for CLS)</p></li>
<li><p>Linear Projections for Global Attention: 2 sets of projections are used to compute attention scores of sliding window attention.</p></li>
</ul>
<p><strong>Paper</strong>: <a class="reference external" href="https://arxiv.org/abs/2004.05150">https://arxiv.org/abs/2004.05150</a></p>
<p><strong>Repository</strong>: <a class="reference external" href="https://huggingface.co/allenai/longformer-base-4096">https://huggingface.co/allenai/longformer-base-4096</a></p>
<p><strong>Architecture</strong>: Not stated.</p>
<p><strong>Tasks</strong>: Not stated.</p>
<p><strong>Release Date</strong>: 2020-04-10</p>
<p><strong>Limitations</strong>: Not stated.</p>
<p><strong>Installation</strong>: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-text-torch-transformers]</span></code></p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">#pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-text-torch-transformers]</span>
<span class="pre">from</span> <span class="pre">vectorhub.encoders.text.torch_transformers</span> <span class="pre">import</span> <span class="pre">Longformer2Vec</span>
<span class="pre">model</span> <span class="pre">=</span> <span class="pre">Longformer2Vec()</span>
<span class="pre">model.encode(&quot;I</span> <span class="pre">enjoy</span> <span class="pre">taking</span> <span class="pre">long</span> <span class="pre">walks</span> <span class="pre">along</span> <span class="pre">the</span> <span class="pre">beach</span> <span class="pre">with</span> <span class="pre">my</span> <span class="pre">dog.&quot;)</span>
<span class="pre">`</span></code></p>
<dl class="py class">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec">
<em class="property">class </em><code class="sig-prename descclassname">vectorhub.encoders.text.torch_transformers.torch_longformers.</code><code class="sig-name descname">Longformer2Vec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'allenai/longformer-base-4096'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="vectorhub.encoders.text.html#vectorhub.encoders.text.base.BaseText2Vec" title="vectorhub.encoders.text.base.BaseText2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">vectorhub.encoders.text.base.BaseText2Vec</span></code></a></p>
<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.bulk_encode">
<code class="sig-name descname">bulk_encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">texts</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">pooling_method</span><span class="o">=</span><span class="default_value">'mean'</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>List<span class="p">[</span>float<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.bulk_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode multiple sentences using transformers.
:param texts: List[str]</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.chunk">
<em class="property">classmethod </em><code class="sig-name descname">chunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lst</span><span class="p">:</span> <span class="n">List</span></em>, <em class="sig-param"><span class="n">chunk_size</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Chunk an iterable object in Python but not a pandas DataFrame.
:param lst: Python List
:param chunk_size: The chunk size of an object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">documents</span> <span class="o">=</span> <span class="p">[{</span><span class="o">...</span><span class="p">}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ViClient</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.definition">
<code class="sig-name descname">definition</code><em class="property"> = &lt;vectorhub.doc_utils.ModelDefinition object&gt;</em><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.definition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>float<span class="p">]</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode words using transformers.
:param text: str</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.is_url_working">
<em class="property">static </em><code class="sig-name descname">is_url_working</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">url</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.is_url_working" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.list_possible_models">
<em class="property">static </em><code class="sig-name descname">list_possible_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.list_possible_models" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.read">
<code class="sig-name descname">read</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.read" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract method to specify the read method to read the data.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.test_word">
<em class="property">property </em><code class="sig-name descname">test_word</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.test_word" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.urls">
<em class="property">property </em><code class="sig-name descname">urls</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.urls" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.validate_model_url">
<em class="property">classmethod </em><code class="sig-name descname">validate_model_url</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_url</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">list_of_urls</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.validate_model_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate the model url belongs in the list of urls. This is to help
users to avoid mis-spelling the name of the model.</p>
<p># TODO:
Improve model URL validation to not include final number in URl string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_url</strong> – The URl of the the model in question</p></li>
<li><p><strong>list_of_urls</strong> – The list of URLS for the model in question</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.vector_length">
<em class="property">property </em><code class="sig-name descname">vector_length</code><a class="headerlink" href="#vectorhub.encoders.text.torch_transformers.torch_longformers.Longformer2Vec.vector_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the vector length of the model.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-vectorhub.encoders.text.torch_transformers">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-vectorhub.encoders.text.torch_transformers" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="vectorhub.encoders.text.vectorai.html" class="btn btn-neutral float-right" title="vectorhub.encoders.text.vectorai package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="vectorhub.encoders.text.tfhub.html" class="btn btn-neutral float-left" title="vectorhub.encoders.text.tfhub package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Vector AI.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>