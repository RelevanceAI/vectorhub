

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>SpeechEmbedding2Vec &mdash; VectorHub 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Trill2Vec" href="encoders.audio.trill2vec.html" />
    <link rel="prev" title="ViImage2Vec" href="encoders.image.vectorai2vec.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> VectorHub
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">What is Vector Hub?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how_to_add_a_model.html">How To Add Your Model To Vector Hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_encoder.html">Guide to using Auto-Encoder</a></li>
</ul>
<p class="caption"><span class="caption-text">Text Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.bert2vec.html">Bert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.albert2vec.html">AlBert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.labse2vec.html">LaBSE2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.use2vec.html">USE2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.use_multi2vec.html">USEMulti2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.legalbert2vec.html">LegalBert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.transformer2vec.html">Transformer2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.vectorai2vec.html">ViText2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Image Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.bit2vec.html">Bit2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.inception2vec.html">Inception2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.resnet2vec.html">ResNet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.inception_resnet2vec.html">InceptionResnet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.mobilenet2vec.html">MobileNet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.vectorai2vec.html">ViImage2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio Encoders</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">SpeechEmbedding2Vec</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-vectorhub.encoders.audio.tfhub.speech_embedding">TFHub</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.trill2vec.html">Trill2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.vggish2vec.html">Vggish2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.yamnet2vec.html">Yamnet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.wav2vec.html">Wav2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.vectorai2vec.html">ViAudio2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Text Bi-Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.use_qa2vec.html">USEQA2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.lareqa_qa2vec.html">LAReQA2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.dpr2vec.html">DPR2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">vectorhub</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">VectorHub</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>SpeechEmbedding2Vec</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/encoders.audio.speech_embedding2vec.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="speechembedding2vec">
<h1>SpeechEmbedding2Vec<a class="headerlink" href="#speechembedding2vec" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-vectorhub.encoders.audio.tfhub.speech_embedding">
<span id="tfhub"></span><h2>TFHub<a class="headerlink" href="#module-vectorhub.encoders.audio.tfhub.speech_embedding" title="Permalink to this headline">¶</a></h2>
<p><strong>Model Name</strong>: Speech Embedding</p>
<p><strong>Vector Length</strong>: 96</p>
<p><strong>Description</strong>:
With the rise of low power speech-enabled devices, there is a growing demand to quickly produce models for recognizing arbitrary
sets of keywords. As with many machine learning tasks, one of the most challenging parts in the model creation process is obtaining
a sufficient amount of training data. In this paper, we explore the effectiveness of synthesized speech data in training small,
spoken term detection models of around 400k parameters. Instead of training such models directly on the audio or low level features
such as MFCCs, we use a pre-trained speech embedding model trained to extract useful features for keyword spotting models. Using this
speech embedding, we show that a model which detects 10 keywords when trained on only synthetic speech is equivalent to a model trained
on over 500 real examples. We also show that a model without our speech embeddings would need to be trained on over 4000 real examples to
reach the same accuracy.</p>
<p><strong>Paper</strong>: <a class="reference external" href="https://arxiv.org/abs/2002.01322">https://arxiv.org/abs/2002.01322</a></p>
<p><strong>Repository</strong>: <a class="reference external" href="https://tfhub.dev/google/speech_embedding/1">https://tfhub.dev/google/speech_embedding/1</a></p>
<p><strong>Architecture</strong>: Not stated.</p>
<p><strong>Tasks</strong>: Not stated.</p>
<p><strong>Limitations</strong>: Not stated.</p>
<p><strong>Installation</strong>: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">vectorhub[encoders-audio-tfhub]</span></code></p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#pip install vectorhub[encoders-audio-tfhub]</span>
<span class="kn">from</span> <span class="nn">vectorhub.encoders.audio.tfhub</span> <span class="kn">import</span> <span class="n">SpeechEmbedding2Vec</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SpeechEmbedding2Vec</span><span class="p">()</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s1">&#39;https://vecsearch-bucket.s3.us-east-2.amazonaws.com/voices/common_voice_en_2.wav&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py class">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec">
<em class="property">class </em><code class="sig-prename descclassname">vectorhub.encoders.audio.tfhub.speech_embedding.</code><code class="sig-name descname">SpeechEmbedding2Vec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_url</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'https://tfhub.dev/google/speech_embedding/1'</span></em>, <em class="sig-param"><span class="n">signature</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'default'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">vectorhub.encoders.audio.base.BaseAudio2Vec</span></code></p>
<dl class="py method">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.bulk_encode">
<code class="sig-name descname">bulk_encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">audios</span></em>, <em class="sig-param"><span class="n">vector_operation</span><span class="o">=</span><span class="default_value">'mean'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.bulk_encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.chunk">
<em class="property">classmethod </em><code class="sig-name descname">chunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lst</span><span class="p">:</span> <span class="n">List</span></em>, <em class="sig-param"><span class="n">chunk_size</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Chunk an iterable object in Python but not a pandas DataFrame.
:param lst: Python List
:param chunk_size: The chunk size of an object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">documents</span> <span class="o">=</span> <span class="p">[{</span><span class="o">...</span><span class="p">}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ViClient</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.definition">
<code class="sig-name descname">definition</code><em class="property"> = &lt;vectorhub.doc_utils.ModelDefinition object&gt;</em><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.definition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">audio</span></em>, <em class="sig-param"><span class="n">vector_operation</span><span class="o">=</span><span class="default_value">'mean'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode the vector.
Example:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">vectorhub.encoders.audio</span> <span class="kn">import</span> <span class="n">SpeechEmbedding2Vec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">SpeechEmbedding2Vec</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.read">
<code class="sig-name descname">read</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">audio</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">new_sampling_rate</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">16000</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.read" title="Permalink to this definition">¶</a></dt>
<dd><p>An method to specify the read method to read the data.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.validate_model_url">
<em class="property">classmethod </em><code class="sig-name descname">validate_model_url</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_url</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">list_of_urls</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.encoders.audio.tfhub.speech_embedding.SpeechEmbedding2Vec.validate_model_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate the model url belongs in the list of urls.</p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="encoders.audio.trill2vec.html" class="btn btn-neutral float-right" title="Trill2Vec" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="encoders.image.vectorai2vec.html" class="btn btn-neutral float-left" title="ViImage2Vec" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Vector AI

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>